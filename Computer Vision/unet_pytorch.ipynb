{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.randn(1, 3, 32, 32)  # input tensor with shape (batch_size, num_channels, height, width)\n",
    "y = F.interpolate(x, scale_factor=2, mode='nearest')  # upsample x by a factor of 2 using nearest-neighbor interpolation\n",
    "print(y.shape)  # torch.Size([1, 3, 64, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        # define other layers here\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        # pass x through other layers here\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class ContractingBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ContractingBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        skip = x  # store the output for the skip connection\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        return x, skip\n",
    "\n",
    "class ExpandingBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ExpandingBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.upsample = nn.ConvTranspose2d(out_channels, out_channels // 2, kernel_size=2, stride=2) # in original U-Net, this is upsampling 2d\n",
    "        \n",
    "    def forward(self, x, skip):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        # concatenate the skip connection\n",
    "        x = torch.cat((x, skip), dim=1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        self.contract1 = ContractingBlock(in_channels, 64)\n",
    "        self.contract2 = ContractingBlock(64, 128)\n",
    "        self.contract3 = ContractingBlock(128, 256)\n",
    "        self.contract4 = ContractingBlock(256, 512) # contraction is happening in x, y dimensions\n",
    "        \n",
    "        self.expand1 = ExpandingBlock(512, 256)\n",
    "        self.expand2 = ExpandingBlock(256, 128)\n",
    "        self.expand3 = ExpandingBlock(128, 64)\n",
    "        \n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Contracting path\n",
    "        x, skip1 = self.contract1(x)\n",
    "        x, skip2 = self.contract2(x)\n",
    "        x, skip3 = self.contract3(x)\n",
    "        x, _ = self.contract4(x)\n",
    "        \n",
    "        # Expanding path\n",
    "        x = self.expand1(x, skip3)\n",
    "        x = self.expand2(x, skip2)\n",
    "        x = self.expand3(x, skip1)\n",
    "\n",
    "        x = self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18 (main, Sep 11 2023, 14:09:26) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b8cc2443dac255f5863d925b738cfe3a24d8333c04bb14f72dfd9c643c8ae38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
