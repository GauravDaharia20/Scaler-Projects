{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pickle\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['accordion', 'airplanes', 'anchor', 'ant', 'BACKGROUND_Google', 'barrel', 'bass', 'beaver', 'binocular', 'bonsai', 'brain', 'brontosaurus', 'buddha', 'butterfly', 'camera', 'cannon', 'car_side', 'ceiling_fan', 'cellphone', 'chair', 'chandelier', 'cougar_body', 'cougar_face', 'crab', 'crayfish', 'crocodile', 'crocodile_head', 'cup', 'dalmatian', 'dollar_bill', 'dolphin', 'dragonfly', 'electric_guitar', 'elephant', 'emu', 'euphonium', 'ewer', 'Faces', 'Faces_easy', 'ferry', 'flamingo', 'flamingo_head', 'garfield', 'gerenuk', 'gramophone', 'grand_piano', 'hawksbill', 'headphone', 'hedgehog', 'helicopter', 'ibis', 'inline_skate', 'joshua_tree', 'kangaroo', 'ketch', 'lamp', 'laptop', 'Leopards', 'llama', 'lobster', 'lotus', 'mandolin', 'mayfly', 'menorah', 'metronome', 'minaret', 'Motorbikes', 'nautilus', 'octopus', 'okapi', 'pagoda', 'panda', 'pigeon', 'pizza', 'platypus', 'pyramid', 'revolver', 'rhino', 'rooster', 'saxophone', 'schooner', 'scissors', 'scorpion', 'sea_horse', 'snoopy', 'soccer_ball', 'stapler', 'starfish', 'stegosaurus', 'stop_sign', 'strawberry', 'sunflower', 'tick', 'trilobite', 'umbrella', 'watch', 'water_lilly', 'wheelchair', 'wild_cat', 'windsor_chair', 'wrench', 'yin_yang']\n"
     ]
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\\\gaura\\\\Documents\\\\GitHub\\\\Scaler-Projects\\\\Computer Vision\\\\Image similarity Understanding Embeddings\\\\101_ObjectCategories\\\\101_ObjectCategories\"\n",
    "dir_list = os.listdir(path)\n",
    "print(dir_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accordion': 55, 'airplanes': 800, 'anchor': 42, 'ant': 42, 'BACKGROUND_Google': 468, 'barrel': 47, 'bass': 54, 'beaver': 46, 'binocular': 33, 'bonsai': 128, 'brain': 98, 'brontosaurus': 43, 'buddha': 85, 'butterfly': 91, 'camera': 50, 'cannon': 43, 'car_side': 123, 'ceiling_fan': 47, 'cellphone': 59, 'chair': 62, 'chandelier': 107, 'cougar_body': 47, 'cougar_face': 69, 'crab': 73, 'crayfish': 70, 'crocodile': 50, 'crocodile_head': 51, 'cup': 57, 'dalmatian': 67, 'dollar_bill': 52, 'dolphin': 65, 'dragonfly': 68, 'electric_guitar': 75, 'elephant': 64, 'emu': 53, 'euphonium': 64, 'ewer': 85, 'Faces': 435, 'Faces_easy': 435, 'ferry': 67, 'flamingo': 67, 'flamingo_head': 45, 'garfield': 34, 'gerenuk': 34, 'gramophone': 51, 'grand_piano': 99, 'hawksbill': 100, 'headphone': 42, 'hedgehog': 54, 'helicopter': 88, 'ibis': 80, 'inline_skate': 31, 'joshua_tree': 64, 'kangaroo': 86, 'ketch': 114, 'lamp': 61, 'laptop': 81, 'Leopards': 200, 'llama': 78, 'lobster': 41, 'lotus': 66, 'mandolin': 43, 'mayfly': 40, 'menorah': 87, 'metronome': 32, 'minaret': 76, 'Motorbikes': 798, 'nautilus': 55, 'octopus': 35, 'okapi': 39, 'pagoda': 47, 'panda': 38, 'pigeon': 45, 'pizza': 53, 'platypus': 34, 'pyramid': 57, 'revolver': 82, 'rhino': 59, 'rooster': 49, 'saxophone': 40, 'schooner': 63, 'scissors': 39, 'scorpion': 84, 'sea_horse': 57, 'snoopy': 35, 'soccer_ball': 64, 'stapler': 45, 'starfish': 86, 'stegosaurus': 59, 'stop_sign': 64, 'strawberry': 35, 'sunflower': 85, 'tick': 49, 'trilobite': 86, 'umbrella': 75, 'watch': 239, 'water_lilly': 37, 'wheelchair': 59, 'wild_cat': 34, 'windsor_chair': 56, 'wrench': 39, 'yin_yang': 60}\n"
     ]
    }
   ],
   "source": [
    "image_dir = {}\n",
    "for val in dir_list:\n",
    "    img_path = os.path.join(path,val)\n",
    "    images = os.listdir(img_path)\n",
    "    image_dir[val] = len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accordion': 55,\n",
       " 'airplanes': 800,\n",
       " 'anchor': 42,\n",
       " 'ant': 42,\n",
       " 'BACKGROUND_Google': 468,\n",
       " 'barrel': 47,\n",
       " 'bass': 54,\n",
       " 'beaver': 46,\n",
       " 'binocular': 33,\n",
       " 'bonsai': 128,\n",
       " 'brain': 98,\n",
       " 'brontosaurus': 43,\n",
       " 'buddha': 85,\n",
       " 'butterfly': 91,\n",
       " 'camera': 50,\n",
       " 'cannon': 43,\n",
       " 'car_side': 123,\n",
       " 'ceiling_fan': 47,\n",
       " 'cellphone': 59,\n",
       " 'chair': 62,\n",
       " 'chandelier': 107,\n",
       " 'cougar_body': 47,\n",
       " 'cougar_face': 69,\n",
       " 'crab': 73,\n",
       " 'crayfish': 70,\n",
       " 'crocodile': 50,\n",
       " 'crocodile_head': 51,\n",
       " 'cup': 57,\n",
       " 'dalmatian': 67,\n",
       " 'dollar_bill': 52,\n",
       " 'dolphin': 65,\n",
       " 'dragonfly': 68,\n",
       " 'electric_guitar': 75,\n",
       " 'elephant': 64,\n",
       " 'emu': 53,\n",
       " 'euphonium': 64,\n",
       " 'ewer': 85,\n",
       " 'Faces': 435,\n",
       " 'Faces_easy': 435,\n",
       " 'ferry': 67,\n",
       " 'flamingo': 67,\n",
       " 'flamingo_head': 45,\n",
       " 'garfield': 34,\n",
       " 'gerenuk': 34,\n",
       " 'gramophone': 51,\n",
       " 'grand_piano': 99,\n",
       " 'hawksbill': 100,\n",
       " 'headphone': 42,\n",
       " 'hedgehog': 54,\n",
       " 'helicopter': 88,\n",
       " 'ibis': 80,\n",
       " 'inline_skate': 31,\n",
       " 'joshua_tree': 64,\n",
       " 'kangaroo': 86,\n",
       " 'ketch': 114,\n",
       " 'lamp': 61,\n",
       " 'laptop': 81,\n",
       " 'Leopards': 200,\n",
       " 'llama': 78,\n",
       " 'lobster': 41,\n",
       " 'lotus': 66,\n",
       " 'mandolin': 43,\n",
       " 'mayfly': 40,\n",
       " 'menorah': 87,\n",
       " 'metronome': 32,\n",
       " 'minaret': 76,\n",
       " 'Motorbikes': 798,\n",
       " 'nautilus': 55,\n",
       " 'octopus': 35,\n",
       " 'okapi': 39,\n",
       " 'pagoda': 47,\n",
       " 'panda': 38,\n",
       " 'pigeon': 45,\n",
       " 'pizza': 53,\n",
       " 'platypus': 34,\n",
       " 'pyramid': 57,\n",
       " 'revolver': 82,\n",
       " 'rhino': 59,\n",
       " 'rooster': 49,\n",
       " 'saxophone': 40,\n",
       " 'schooner': 63,\n",
       " 'scissors': 39,\n",
       " 'scorpion': 84,\n",
       " 'sea_horse': 57,\n",
       " 'snoopy': 35,\n",
       " 'soccer_ball': 64,\n",
       " 'stapler': 45,\n",
       " 'starfish': 86,\n",
       " 'stegosaurus': 59,\n",
       " 'stop_sign': 64,\n",
       " 'strawberry': 35,\n",
       " 'sunflower': 85,\n",
       " 'tick': 49,\n",
       " 'trilobite': 86,\n",
       " 'umbrella': 75,\n",
       " 'watch': 239,\n",
       " 'water_lilly': 37,\n",
       " 'wheelchair': 59,\n",
       " 'wild_cat': 34,\n",
       " 'windsor_chair': 56,\n",
       " 'wrench': 39,\n",
       " 'yin_yang': 60}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Dense , MaxPooling2D,concatenate, Add,BatchNormalization,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Inception Module\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m conv1 \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[43mf1\u001b[49m,(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(layer_in)\n\u001b[0;32m      3\u001b[0m conv3 \u001b[38;5;241m=\u001b[39m Conv2D(f2,(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m),padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(layer_in)\n\u001b[0;32m      4\u001b[0m conv3 \u001b[38;5;241m=\u001b[39m Conv2D(f2,(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m3\u001b[39m),padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m)(conv3)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f1' is not defined"
     ]
    }
   ],
   "source": [
    "# Inception Module\n",
    "conv1 = Conv2D(f1,(1,1),padding = \"same\",activation=\"relu\")(layer_in)\n",
    "conv3 = Conv2D(f2_in,(1,1),padding = \"same\",activation=\"relu\")(layer_in)\n",
    "conv3 = Conv2D(f2_out,(3,3),padding = \"same\",activation=\"relu\")(conv3)\n",
    "\n",
    "conv5 = Conv2D(f3_in,(1,1),padding = \"same\",activation=\"relu\")(layer_in)\n",
    "conv5 = Conv2D(f3_out,(5,5),padding = \"same\",activation=\"relu\")(conv5)\n",
    "\n",
    "pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),activation=\"relu\")(layer_in)\n",
    "pool = Conv2D(pool,(1,1),padding=\"same\",activation=\"relu\")(pool)\n",
    "\n",
    "layer_out = concatenate([conv1,conv3,conv5,pool],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identity layer\n",
    "def identity_block(x,filter):\n",
    "    f1,f2,f3 = filter\n",
    "    x_skip = x\n",
    "\n",
    "    x = Conv2D(f1,(1,1),padding=\"valid\")(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(f2,(3,3),padding=\"same\")(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "\n",
    "    x = Conv2D(f3,(1,1),padding=\"valid\")(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "\n",
    "    x = Add()[x,x_skip]\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolutional_block(x, s,filter):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    F1,F2,F3 =filter\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(F1, (1,1), padding = 'valid', strides = (s,s))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(F2, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 3\n",
    "    x = tf.keras.layers.Conv2D(F3, (1,1), padding = 'valid')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv2D(F3, (1,1),padding = 'valid', strides = (s,s))(x_skip)\n",
    "    x_skip = tf.keras.layers.BatchNormalization(axis=3)(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94765736/94765736 [==============================] - 30s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(weights='imagenet',\n",
    "                         include_top=False,\n",
    "                         input_shape=(224, 224, 3),\n",
    "                         pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pickle\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"caltech101//101_ObjectCategories\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9144 files belonging to 102 classes.\n",
      "72/72 [==============================] - 36s 504ms/step\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "generator = tf.keras.utils.image_dataset_from_directory(file_path,\n",
    "                                            shuffle=False,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                            image_size=(224,224))\n",
    "\n",
    "num_images = len(generator.file_paths)\n",
    "num_epochs = int(math.ceil(num_images / BATCH_SIZE))\n",
    "\n",
    "start_time = time.time()\n",
    "feature_list = []\n",
    "feature_list = model.predict(generator, num_epochs)\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9144, 2048)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.9329284 , 0.        , ..., 0.        , 1.7577997 ,\n",
       "        0.        ],\n",
       "       [0.3294776 , 1.4616555 , 0.26246104, ..., 0.0149948 , 0.69723994,\n",
       "        0.16061266],\n",
       "       [0.        , 0.01286209, 0.0853259 , ..., 2.158318  , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 2.995534  , 0.04210735, ..., 0.03813392, 0.02419601,\n",
       "        0.01063317],\n",
       "       [0.        , 0.32350093, 0.        , ..., 0.05312152, 0.35811096,\n",
       "        0.        ],\n",
       "       [0.02182099, 0.8200785 , 0.54516566, ..., 0.48404437, 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "norm(feature_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50.238068, 48.074726, 29.718513, ..., 46.148754, 45.459896,\n",
       "       45.07316 ], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2048,) (9144,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indx, feature \u001b[38;5;129;01min\u001b[39;00m  \u001b[38;5;28menumerate\u001b[39m(feature_list):\n\u001b[1;32m----> 2\u001b[0m     feature_list[indx] \u001b[38;5;241m=\u001b[39m \u001b[43mfeature\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mnorm\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2048,) (9144,) "
     ]
    }
   ],
   "source": [
    "for indx, feature in  enumerate(feature_list):\n",
    "    feature_list[indx] = feature/norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
