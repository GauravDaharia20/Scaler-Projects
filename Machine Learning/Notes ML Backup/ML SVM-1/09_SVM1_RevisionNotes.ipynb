{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr4InsQBBJ-v"
      },
      "source": [
        "## Content\n",
        "\n",
        "- Problem Statement\n",
        "- Geometric Intuition of SVM\n",
        "  - Hard Margin SVM\n",
        "  \n",
        "- Soft Margin SVM\n",
        "  - Algebric Intuition of SVM\n",
        "- Intution of Hinge Loss\n",
        "- SVM Imbalance\n",
        "  \n",
        "- Code Implementation of Linear SVM\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ud588DbfCvPP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgEIfnwZ8oTH"
      },
      "source": [
        "### Problem Statement\n",
        "\n",
        "Imagine youself as a Data Scientist at Google. </br>\n",
        "You've been asked to come up with model to classify emails as either **Spam** or **Ham**.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "ec15yP1v3t1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVMs\n",
        "- Popular in 2000's ( late 90s )\n",
        "- Kernel SVM\n",
        "- Theoritically they are best.\n",
        "  - (In practice better algorithms exists)\n",
        "- Less frequently used nowadays\n",
        "- Challenging Maths"
      ],
      "metadata": {
        "id": "EzWHabjL3YAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "3AgHhaSkCwpC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1I9nSCibTgH"
      },
      "source": [
        "### Geometric intution behind SVM\n",
        "\n",
        "The main idea behind SVM is to\n",
        "- find the line or plane that can\n",
        "- best seperate the given classes.\n",
        "\n",
        "\\\n",
        "Let us try to understand this through a simple example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfLYwoEtVAg3"
      },
      "source": [
        "Suppose,\n",
        "\n",
        "We have some datapoints that belong to two different classes.\n",
        "- +ve class\n",
        "- -ve class\n",
        "\n",
        "\\\n",
        "#### How do you divide the +ve samples from the -ve ones?\n",
        "\n",
        "Using a **line/hyperplane**.\n",
        "\n",
        "```\n",
        "Hyperplanes can be defined as decision boundaries that help classify the datapoints.\n",
        "```\n",
        "\n",
        "But there can be multiple lines/hyperplanes.\n",
        "\n",
        "\\\n",
        "#### So which line/hyperplane should we choose?\n",
        "\n",
        "Imagine, </br>\n",
        "We have two different **hyperplanes**.\n",
        "- $\\pi_1$ and $\\pi_2$\n",
        "\n",
        "\\\n",
        "<img src='https://drive.google.com/uc?id=1lFAoAj0_EimHorfMbhySFQLZlErMFq1W' height='500' width='400'>\n",
        "\n",
        "\\\n",
        "#### Which hyperplane is better for separating the datapoints?\n",
        "\n",
        "- Option A: $\\pi_1$\n",
        "- Option B: $\\pi_2$\n",
        "\n",
        "Answer: Hyperplane $\\pi_2$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "dySWqHn8C07p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### But how can we say that?\n",
        "\n",
        "Because,\n",
        "- the minimum distance of hyperplane $\\pi_2$\n",
        "- from the nearest existing data points is large.\n",
        "\n",
        "\\\n",
        "Intuitively,\n",
        "- If we look at the hyperplane $\\pi_1$\n",
        "- and we draw two hyperplanes parallel to $\\pi_1$ from the closest +ve & -ve datapoint to $\\pi_1$\n",
        "- we can see the gap between these two parallel drawn hyperplanes.\n",
        "\n",
        "Let's call this gap as **margin_1** wrt hyperplane $\\pi_1$.\n",
        "\n",
        "\\\n",
        "Similarly,\n",
        "- we can get **margin_2** wrt hyperplane $\\pi_2$.\n",
        "\n",
        "Now we can see that,\n",
        "- margin_2 is much larger than margin_1.\n",
        "\n",
        "Hence,\n",
        "- we pick that hyperplane $\\pi$ that results in largest margin."
      ],
      "metadata": {
        "id": "WRAB-b78Cktx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "5kewcQR-C2Nz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Why do we need the margin to be large?\n",
        "\n",
        "The hyperplane is drawn with a view of putting in\n",
        "- the **widest street** that separates the +ve & -ve samples.\n",
        "\n",
        "\\\n",
        "Therefore,\n",
        "- the larger the margin,\n",
        "- the better the separation.\n",
        "\n",
        "\\\n",
        "Such classifiers where,\n",
        "- we want the margin to be as large as possible\n",
        "- are called **margin-maximizing classifiers**.\n",
        "\n",
        "\\\n",
        "```\n",
        "NOTE:\n",
        "Distances from datapoints are measured perpendicular to any of the hyperplanes.\n",
        "```"
      ],
      "metadata": {
        "id": "YZ3GU2XwCm7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "QUIZ 1:\n",
        "\n",
        "Q. What do you mean by generalization in terms of SVM?\n",
        "\n",
        "A. How far the hyperplane is from the training datapoints\n",
        "B. How accurately the SVM can predict outcomes for unseen data\n",
        "C. How accurately the SVM classifies training datapoints\n",
        "\n",
        "ANS:\n",
        "B. How accurately the SVM can predict outcomes for unseen data\n",
        "```"
      ],
      "metadata": {
        "id": "wLUKXPeTuFAk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "PhvP1hiGBw-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### How do we define these hyperplanes?\n",
        "\n",
        "Recall from regression models, </br>\n",
        "we define a hyperplane as:\n",
        "- $\\pi : w^Tx+b = 0$\n",
        "\n",
        "\\\n",
        "Let's assume, </br>\n",
        "the parallel hyperplanes are defined as:\n",
        "- For $\\pi^+$,\n",
        "  - $w^Tx+b = 1$\n",
        "- For  $\\pi^-$,\n",
        "  - $w^Tx+b = -1$\n",
        "\n",
        "\\\n",
        "<img src='https://drive.google.com/uc?id=10DaNlGobo-V7GOu9Qr2PP2D_UBnnqe1Y' height='500' width='450'>\n",
        "\n"
      ],
      "metadata": {
        "id": "NzDJvg9gug3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "OlB7w0t3C3-u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqZ1h8asLJbU"
      },
      "source": [
        "Let's summarize everything.\n",
        "\n",
        "\\\n",
        "We have a bunch of +ve & -ve datapoints.\n",
        "\n",
        "- Let's say $\\pi$ is a margin-maximizing hyperplane,\n",
        "\n",
        "\\\n",
        "  - $\\pi^+$ is the positive hyperplane parallel to $\\pi$ and\n",
        "    - touching the closest postive points to the $\\pi$\n",
        "  - $\\pi^-$ is the +ve hyerplane  parallel to $\\pi$ and\n",
        "    - touching the closest -ve points to the $\\pi$\n",
        "\n",
        "\\\n",
        "- $d$ is margin i.e., distance between $\\pi^+$ and $\\pi^-$\n",
        "- We want this margin to be as large as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "raWrc5BoB8AJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What will be the length of the margin if $||w|| \\neq 1$?\n",
        "\n",
        "Recall from linear algebra,\n",
        "\n",
        "\\\n",
        "If we rearrange the equations for $\\pi^+$ and $\\pi^-$,\n",
        "- $w^Tx+b = 1 $ </br>\n",
        "  $\\Rightarrow$ $w^Tx+b -1 = 0 $\n",
        "- $w^Tx+b = -1 $ </br>\n",
        "  $\\Rightarrow$ $w^Tx+b+1 = 0 $\n",
        "\n",
        "\\\n",
        "If measured from the origin,\n",
        "- the distance of hyperplane $\\pi^+$ can be defined as\n",
        "  - $ d(0, \\pi^+) = \\frac{b-1}{||w||}$\n",
        "\n",
        "- the distance of hyperplane $\\pi^-$ can be defined as\n",
        "  - $ d(0, \\pi^-) = \\frac{b+1}{||w||}$\n",
        "\n",
        "\\\n",
        "Hence,\n",
        "- the distance between the two hyperplanes will be\n",
        "- $\\frac{b+1}{||w||} - \\frac{b-1}{||w||}$\n",
        "\n",
        "\\\n",
        "$\\Rightarrow$ Margin i.e., </br> $d( \\pi^+,\\pi^-) = \\frac{2}{||w||}$\n",
        "\n",
        "\\\n",
        "<img src='https://drive.google.com/uc?id=1l1mOyJbXlB5vHnQISpy_EmZqJvTMuH7E' height='450' width='450'>"
      ],
      "metadata": {
        "id": "qpXfsv-sB5O3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7n0sQSqBQwu"
      },
      "source": [
        "Now, our goal is\n",
        "- to maximize this margin $\\frac{2}{||w||}$ in order to\n",
        "- obtain the best possible separation between the two classes.\n",
        "\n",
        "\\\n",
        "#### What will be the parameters for the margin $\\frac{2}{||w||}$?\n",
        "\n",
        "- Weight ($w$)\n",
        "- Constant ($b$)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Id_LX4PiBj0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What if we define the hyperplanes like this?\n",
        "- $\\pi^+$ as $w^Tx+b=k$\n",
        "- $\\pi^-$ as $w^Tx+b=-k$\n",
        "\n",
        "\\\n",
        "If we take $k=10$ then,\n",
        "- $\\pi^+:w^Tx+b=10$\n",
        "- $\\pi^-: w^Tx+b=-10$\n",
        "\n",
        "\\\n",
        "Hence, </br>\n",
        "we get our margin as:\n",
        "- $\\frac{20}{||w||}$\n",
        "\n",
        "\\\n",
        "Now we will maximize this margin on\n",
        "- weight ($w$) and\n",
        "- constant ($b$)\n",
        "\n",
        "\\\n",
        "<img src='https://drive.google.com/uc?id=1sdtB4cTIJ4-bEWa_8cGnz-AbCLAm9SbU' height='450' width='450'>\n",
        "\n",
        "\\\n",
        "Since the margin does not change,\n",
        "- with respect to $w$ and $b$\n",
        "\n",
        "\\\n",
        "<img src='https://drive.google.com/uc?id=1SP2ZwDUV3AEzDVHAGzfraPYMcwrs9Ppf' height='450' width='450'>\n",
        "\n",
        "It doesn't matter if we take\n",
        "- $+1,-1$ or $k,-k$\n",
        "\n",
        "Hence,\n",
        "- for mathematical simplicity,\n",
        "- we take $+1, -1$"
      ],
      "metadata": {
        "id": "9-HLeEg-BlVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "QUIZ 2:\n",
        "\n",
        "Q. If,\n",
        "- π+ : w^T * x + b = 40\n",
        "- π- : w^T * x + b = -50\n",
        "then margin will be:\n",
        "\n",
        "A. 10/||w||\n",
        "B. 40/||w||\n",
        "C. 50/||w||\n",
        "D. 90/||w||\n",
        "\n",
        "ANS:\n",
        "D. 90/||w||\n",
        "```"
      ],
      "metadata": {
        "id": "_VzhckuQcgbY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Syry9VyiBsuC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFVM0l7bzA2u"
      },
      "source": [
        "### <b> SVM Demo </b>\n",
        "\n",
        "https://jgreitemann.github.io/svm-demo\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=149Xs-dDaEhXH8m90fiSlT0SPlUchUo2T' height='400' width='650'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wis_i8wnbl24"
      },
      "source": [
        "### Hard Margin SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krbxUrvIDli4"
      },
      "source": [
        "Now, as we discussed\n",
        "- our aim is to maximize the margin.\n",
        "\n",
        "\\\n",
        "#### So how can we perform optimization here?\n",
        "\n",
        "Let's look at an example to understand this.\n",
        "\n",
        "\\\n",
        "What will be the value of a +ve datapoint which lies on the hyperplane $\\pi^+$?\n",
        "- 1 ,\n",
        "- since $\\pi^+: w^Tx+b=1$\n",
        "\n",
        "```\n",
        "Case 1:\n",
        "```\n",
        "What will be the value of the +ve datapoints which lie beyond the hyperplane $\\pi^+$?\n",
        "- greater than 1 ,\n",
        "- hence $\\pi^+: w^Tx+b > 1$\n",
        "\n",
        "\\\n",
        "Similarly,\n",
        "\n",
        "```\n",
        "Case 2:\n",
        "```\n",
        "What will be the value of the -ve datapoints which lie beyond the hyperplane $\\pi^-$ ?\n",
        "- less than -1 ,\n",
        "- hence $\\pi^+: w^Tx+b < -1$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "AynYlxjaQShz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, </br>\n",
        "for mathematical convenience </br>\n",
        "we introduce a term $y_i$ such that:\n",
        "\n",
        "- $y_i$ = +1 for +ve samples\n",
        "- $y_i$ = -1 for -ve samples\n",
        "\n",
        "\\\n",
        "Therefore,\n",
        "- $\\pi^+: y_i(w^Tx+b) > 1$\n",
        "- $\\pi^+: y_i(w^Tx+b) < -1$\n",
        "\n",
        "\\\n",
        "We can club both the cases and say,\n",
        "- we maximize the margin such that\n",
        "- for all n samples,\n",
        "- our $(w^Tx_i + b)y_i \\geq 1 $\n",
        "\n",
        "\\\n",
        "<img src='https://drive.google.com/uc?id=1TdMTmU8OeS-jZss9Io9VD3LKKTcfQG9W' height='500' width='400'>\n",
        "\n",
        "\\\n",
        "#### But how does this work?\n",
        "\n",
        "- For +ve samples,\n",
        "  - $y_i$ = +1\n",
        "  - $(w^Tx_i + b)$ will be +ve since it will be $\\geq$ 1\n",
        "  - hence, (+ve) multiplied by (+ve) makes positive.\n",
        "- For -ve samples,\n",
        "  - $y_i$ = -1\n",
        "  - $(w^Tx_i + b)$ will be -ve since it will be $\\leq$ 1\n",
        "  - hence, (-ve) multiplied by (-ve) makes positive."
      ],
      "metadata": {
        "id": "EjwinU3ZMkBA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6z4i9Y-yPu5"
      },
      "source": [
        "Example -\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1VgUbWlosavzPc9ftYrdt0JntpwZP6c1_' height='400' width='750'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "F0oZNsncQUa3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-syRX8RyQG9"
      },
      "source": [
        "#### But why the $(w^Tx_i + b)y_i \\geq 1$ constraint?\n",
        "\n",
        "Our goal is to\n",
        "- seperate the two classes completely\n",
        "- with margin as maximum as possible.\n",
        "\n",
        "\\\n",
        "With this constraint:\n",
        "- all +ve datapoints should lie beyond $\\pi^+$\n",
        "- all -ve datapoints should lie beyond $\\pi^-$\n",
        "\n",
        "\\\n",
        "Thus,\n",
        "- it expects the hyperplane to have zero errors since,\n",
        "- it does not want any datatpoint to belong\n",
        "- to the wrong side of the parallel hyperplanes."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To summarise, </br>\n",
        "\n",
        "If we strictly impose that:\n",
        "- all instances must be off the street (margin)\n",
        "- and on the correct side,\n",
        "- then this is called **Hard Margin classification**.\n"
      ],
      "metadata": {
        "id": "3ljdr2jXP0Sy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "aeWjUlpNQVwP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxw5AaHMFNzv"
      },
      "source": [
        "#### When would Linear SVM with Hard Margin fail?\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1Sieivv5mv2kFdKdXdjcc51bLTybnq0iC' height='400' width='500'>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KApoedvotwV8"
      },
      "source": [
        "```\n",
        "QUIZ 3:\n",
        "\n",
        "Q. What do you mean by a hard margin?\n",
        "\n",
        "A. The SVM allows no error in classification.\n",
        "B. The SVM allows some error in classification.\n",
        "C. The SVM allows high error in classification.\n",
        "\n",
        "ANS:\n",
        "A) The SVM allows very low error in classification.\n",
        "```\n",
        "```\n",
        "Explanation:\n",
        "\n",
        "A hard margin means that an SVM is very rigid in classification and\n",
        "tries to work extremely well on the training set causing overfitting.\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "6RDn7JeoQXBk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybT8Fw_dbyX6"
      },
      "source": [
        "### Soft Margin SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JP8teuA0xWYq"
      },
      "source": [
        "#### What if data is not perfectly linearly seperable?\n",
        "\n",
        "Imagine a dataset where,\n",
        "- some data points are on the wrong side.\n",
        "\n",
        "This is what we call **almost linearly separable** data.\n",
        "\n",
        "\\\n",
        "<img src='https://drive.google.com/uc?id=15l_dsx_MUv7PB8YbQPJPWW0RQj2lueI3' height='420' width='475'>\n",
        "\n",
        "\\\n",
        "#### How to account for these data points?\n",
        "\n",
        "Imagine,\n",
        "- A $+ve$ labelled data point $ \\ x_1 $\n",
        "- at 0.5 unit distance in between $ \\pi \\ and \\ \\pi^+ $\n",
        "\n",
        "\\\n",
        "#### What will be the value of $ y_i(w^Tx_i+b) $ for $x_1$?\n",
        "\n",
        "- $\\ y_1(w^Tx_1+b)$ = 0.5 = 1 - 0.5,\n",
        "- where 0.5 is error $ \\zeta_1 $\n",
        "\n",
        "\\\n",
        "#### Does this equation $(w^Tx_i+b)y_i >= 1 - \\zeta_i$ holds true for -ve points too?\n",
        "\n",
        "**Yes**\n",
        "\n",
        "Imagine,\n",
        "\n",
        "- A $-ve$ labelled data point $ \\ x_2 $\n",
        "- at 0.5 unit distance in between $ \\pi \\ and \\ \\pi^- $\n",
        "\n",
        "\\\n",
        "#### What will be the value of $ y_i(w^Tx_i+b) $ for $x_2$?\n",
        "\n",
        "- $\\ y_2(w^Tx_2+b)$ = 0.5 = 1 - 0.5,\n",
        "- where 0.5 is $ \\zeta_2 $\n",
        "\n",
        "\\\n",
        "<img src='https://drive.google.com/uc?id=19Jy5DJE9zZMqmxos8FWhH-RJdonqfIi9' height='450' width='400'>\n",
        "\n",
        "\\\n",
        "So,\n",
        "- $ \\zeta_i = 0$ for all correctly placed points.\n",
        "- $ \\zeta_i > 0$ for all incorrectly placed points.\n",
        "\n",
        "\\\n",
        "Now, our optimization problem becomes:\n",
        "\n",
        "- $ max \\ \\frac{2}{||w||} $ i.e., the margin\n",
        "- along with minimizing error $ \\zeta_i's $\n",
        "\n",
        "because we're try to get the best possible classificaton.\n",
        "\n",
        "\\\n",
        "#### Can we think of another way to write this?\n",
        "\n",
        "Reciprocating above equation,\n",
        "\n",
        "- $ min \\ \\frac{||w||}{2} $ with $ \\zeta_i's $\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "dMz47Xp2fDHu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_y3iN7EeZie"
      },
      "source": [
        "#### What do you think our goal here is ?\n",
        "\n",
        "- We want to maximize the margin\n",
        "- and minimize data points having $ \\zeta_i > 0$,\n",
        "- so we should minimize the error $ \\zeta_i's $.\n",
        "\n",
        "\\\n",
        "Now the optimization function changes to:\n",
        "- $ min_{w,b} \\ \\frac{||w||}{2} + C \\sum_{i=1}^N \\zeta_i$\n",
        "\n",
        "- such that $(w^Tx_i+b)y_i >= 1 - \\zeta_i$\n",
        "\n",
        "- for all $i : 1 \\rightarrow N$\n",
        "\n",
        "-  $ \\zeta_i >= 0 $.\n",
        "\n",
        "\\\n",
        "This is called as **SVM with soft margin** which we use when we have **almost linearly seperable** data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "wlPh3dJ1Q6Uo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What's the use of $C$ here?\n",
        "\n",
        "$C$ is a hyperparameter.\n",
        "\n",
        "\\\n",
        "It controls whether we have to focus on\n",
        "- maximizing the margin or\n",
        "- minimizig the errors $ \\zeta_i's $\n",
        "\n",
        "\\\n",
        "#### What if the value of $C$ becomes zero?\n",
        "\n",
        "As $C \\downarrow$\n",
        "- more imp will be given to maximize the margin\n",
        "- so the model Underfits.\n",
        "\n",
        "\\\n",
        "<img src='https://drive.google.com/uc?id=1-9SaALYoiCntg7xzQCqZQVLxuHUgsZ0L' height='400' width='500'>\n",
        "\n",
        "\\\n",
        "#### What will happen if $C$ is very large?\n",
        "\n",
        "As $C \\uparrow$\n",
        "- more imp will be given to the errors\n",
        "- so the model Overfits.\n",
        "\n",
        "\\\n",
        "<img src='https://drive.google.com/uc?id=1_KGPoD7bcYJcjMdPWTpRdhcflo6krjyc' height='400' width='500'>\n",
        "\n",
        "\\\n",
        "Therefore,\n",
        "- we need to find a balance here.\n",
        "\n"
      ],
      "metadata": {
        "id": "sByBnCX4QSCD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPxPZ_mWy7ow"
      },
      "source": [
        "```\n",
        "QUIZ 4:\n",
        "\n",
        "Q. What would happen when you use very large value of C?\n",
        "\n",
        "A. We can still classify training data correctly for given setting of hyperparameter C.\n",
        "B. We cannot classify training data correctly for given setting of hyperparameter C.\n",
        "C. Can’t say for sure\n",
        "\n",
        "ANS:\n",
        "A. We can still classify training data correctly for given setting of hyperparameter C.\n",
        "```\n",
        "```\n",
        "Explanation:\n",
        "\n",
        "For large values of C,\n",
        "- the penalty for misclassifying points is very high,\n",
        "- so the decision boundary will perfectly separate the data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "zutnW--UWM-E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE0aviGtGRLb"
      },
      "source": [
        "### Algebric intuition behind SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWVpeKMzEEhk"
      },
      "source": [
        "We saw that,\n",
        "- Soft Margin SVMs are defined as:\n",
        "- $min$ <sub> $(w,b)$ </sub> $\\frac{||w||}{2}$ + $C\\frac{1}{N}$$\\sum_{i=1}^N \\zeta_i$\n",
        "\n",
        "\\\n",
        "If we look closely,\n",
        "- the term $\\frac{1}{N}$$\\sum_{i=1}^N \\zeta_i$\n",
        "- is the error which we try to minimize.\n",
        "\n",
        "\\\n",
        "Since $ζ_i$ will be non zero,\n",
        "for data points which are\n",
        "- either inside the margin\n",
        "- or are misclassified.\n",
        "\n",
        "\\\n",
        "**Note:** </br>\n",
        "We refer to the term $\\frac{1}{N}$$\\sum_{i=1}^N \\zeta_i$ as **Hinge Loss**."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "4lcoXsNBPmGV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we now look,\n",
        "- the term $\\frac{||w||}{2}$\n",
        "\n",
        "Geometrically,\n",
        "- $\\frac{||w||}{2}$ is used to have maximum margin.\n",
        "\n",
        "Algebraically,\n",
        "- $\\frac{||w||}{2}$ is just $\\frac{1}{2}$ of L2-Regularization.\n",
        "\n",
        "\\\n",
        "Also, </br>\n",
        "$C$ becomes analogous to our regularization hyperparameter (λ).\n",
        "\n",
        "\\\n",
        "Therefore, </br>\n",
        "we can interpret our Soft-Margin SVM as   \n",
        " - $C$ HingeLoss $+\\frac{1}{2}$ L2Reg\n"
      ],
      "metadata": {
        "id": "rQQSnLFBPnYS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "G4ueOjz8nCKE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us5L2La-jl8U"
      },
      "source": [
        "### Intuition of Hinge Loss\n",
        "\n",
        "\\\n",
        "<img src='https://drive.google.com/uc?id=1G0h0PNfMntRh7ncndEOZiVcNLBI13VKJ' height='400' width='550'>\n",
        "\n",
        "\\\n",
        "Let's say\n",
        "- we define our hyperplane $w^Tx+b$ as $f(x_i)$.\n",
        "- and assume our x-axis to be:\n",
        " - $z_i = y_if(x_i)$\n",
        "\n",
        "```\n",
        "Case 1:\n",
        "```\n",
        "If $z_i \\geq 1$\n",
        "- or we can say $w^Tx+b \\geq 1$\n",
        "\n",
        "Then $\\zeta_i = 0$\n",
        "- i.e., the distance of $x_i$ from $\\pi_+ = 0$\n",
        "- meaning that the point lies beyond $\\pi_+$\n",
        "\n",
        "\\\n",
        "```\n",
        "Case 2:\n",
        "```\n",
        "If $z_i = 0$\n",
        "- or we can say $w^Tx+b = 0$\n",
        "\n",
        "Then $\\zeta_i = 1$\n",
        "- i.e., the distance of $x_i$ from $\\pi_+ = 1$\n",
        "- meaning that the point lies on $\\pi$\n",
        "\n",
        "\\\n",
        "```\n",
        "Case 3:\n",
        "```\n",
        "If $z_i = -1$\n",
        "- or we can say $w^Tx+b = -1$\n",
        "\n",
        "Then $\\zeta_i = 2$\n",
        "- i.e., the distance of $x_i$ from $\\pi_+ = 2$\n",
        "- meaning that the point lies on $\\pi_-$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "QUIZ 5:\n",
        "\n",
        "Q. x1,x2,x3 are -ve datapoints which are 0.2, 3.0, 1.0 at unit distance from π-,\n",
        "what will be the respective ζi?\n",
        "\n",
        "A. 0.8, -2.0, 0.0\n",
        "B. 0.2, 3.0, 1.0\n",
        "C. 0.8, 2.0, 0.0\n",
        "\n",
        "ANS:\n",
        "B. 0.2, 3.0, 1.0\n",
        "```"
      ],
      "metadata": {
        "id": "8VLlR4R_di0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "aReSzuHVzsCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What can we conclude from the graph above?\n",
        "\n",
        "1. Error cannot be negative.\n",
        "  - $\\zeta_i >= 0$\n",
        "2. A/C to the constraint,\n",
        "  - $y_i (w^Tx+b) > 1 - \\zeta_i$\n",
        "\n",
        "$~~~~~~~~~~~~ \\Rightarrow z_i > 1 - \\zeta_i$\n",
        "\n",
        "$~~~~~~~~~~~~ \\Rightarrow \\zeta_i \\geq 1- z_i$\n",
        "\n",
        "\\\n",
        "**Note:**\n",
        "\n",
        "As $z_i$ increases,\n",
        "- $\\zeta_i$ will reduce\n",
        "- but it'll not go below zero.\n",
        "\n",
        "As $z_i$ decreases,\n",
        "- $\\zeta_i$ will increases.\n",
        "\n",
        "\\\n",
        "We can actually combine these two eqns into: </br>\n",
        "\n",
        "**Hinge Loss** </br>\n",
        "$ ~~~~~ \\Rightarrow \\zeta_i = max ~ (0, 1-z_i)$"
      ],
      "metadata": {
        "id": "sYk55lihvJ7J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "SXKUjsJAhr-0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opYVXf-Djkoc"
      },
      "source": [
        "### Comparison with Log Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://drive.google.com/uc?id=1zpPvhQLQtp-I4FU4YwOkLZQJIG3cqk3H' height='400' width='550'>\n",
        "\n",
        "\\\n",
        "#### What happens if $y_i ~ \\epsilon ~ \\{-1, +1\\}$ for LogLoss?\n",
        "\n",
        "- If, $y_i ~ \\epsilon ~ \\{-1, +1\\}$\n",
        "\n",
        "- Then, </br>\n",
        "LogLoss\n",
        "= $ ∑_{i=1}^{n} log( 1 + e^{(-z_i))} )$\n",
        "\n",
        "$~~~~~~~~~~~~~~~~~~~~~$ = $∑_{i=1}^{n} log( 1 + e^{( -y_i (w^Tx_i + b))} )$\n",
        "\n",
        "\\\n",
        "We will not be deriving how we get this equation."
      ],
      "metadata": {
        "id": "zVD2Gmiehs0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "FNfLrg_IRueZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--d4Ft-bLEGO"
      },
      "source": [
        "### SVM Imbalance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHcvOFGDBx-j"
      },
      "source": [
        "#### Are SVMs affected by class imbalance?\n",
        "\n",
        "\n",
        "If we look at optimization problem,\n",
        "\n",
        "\\\n",
        "Only a few datapoints will be contributing to the hinge loss ($\\zeta_i$).\n",
        "- These points are called **Support Vectors**.\n",
        "\n",
        "\n",
        "Hence, SVM will only be affected\n",
        "- if there is imbalance in the no. of support vectors from each class.\n",
        "\n",
        "\\\n",
        "#### Should we use SVM as the baseline model if we have imbalanced data?\n",
        "\n",
        "Not necessarily.\n",
        "\n",
        "Bcoz the balance in no. of support vectors from each class can't be guranteed.\n",
        "\n",
        "\\\n",
        "**Note:** </br>\n",
        "To handle imbalance in dataset,\n",
        "- either use class weights\n",
        "- or rebalance you data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "QUIZ 6:\n",
        "\n",
        "Q. SVM will be impacted if there's an imbalance in the no. of datapoints belonging to each class?\n",
        "\n",
        "A. True\n",
        "B. False\n",
        "\n",
        "ANS:\n",
        "B. False\n",
        "```\n",
        "```\n",
        "Explanation:\n",
        "\n",
        "SVM will only be affected if there is imbalance in the number of support vectors from each class.\n",
        "```"
      ],
      "metadata": {
        "id": "maqL0wxD24CA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "pPE_5qrzRvlW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OJQU1Z6K5by"
      },
      "source": [
        "### Code implementation of Linear SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-P3l-MZwG6L9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn import feature_extraction, model_selection, naive_bayes, metrics, svm\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wI5JevCrG6Jn",
        "outputId": "d0945349-4ea2-4f30-f9e2-75b965499c69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QViUZJ5UIBCgxB_qbOXTLs_2V48w7MWo\n",
            "To: /content/Spam_processed.csv\n",
            "\r  0% 0.00/767k [00:00<?, ?B/s]\r 68% 524k/767k [00:00<00:00, 4.28MB/s]\r100% 767k/767k [00:00<00:00, 5.50MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1QViUZJ5UIBCgxB_qbOXTLs_2V48w7MWo\n",
        "\n",
        "df = pd.read_csv('Spam_processed.csv', encoding='latin-1')\n",
        "df.dropna(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_pDRwUXwHfVW",
        "outputId": "3e07fd61-a54e-493e-a9d3-221abd945bab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      type                                            message  \\\n",
              "0        0  Go until jurong point, crazy.. Available only ...   \n",
              "1        0                      Ok lar... Joking wif u oni...   \n",
              "2        1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3        0  U dun say so early hor... U c already then say...   \n",
              "4        0  Nah I don't think he goes to usf, he lives aro...   \n",
              "...    ...                                                ...   \n",
              "5567     1  This is the 2nd time we have tried 2 contact u...   \n",
              "5568     0              Will Ì_ b going to esplanade fr home?   \n",
              "5569     0  Pity, * was in mood for that. So...any other s...   \n",
              "5570     0  The guy did some bitching but I acted like i'd...   \n",
              "5571     0                         Rofl. Its true to its name   \n",
              "\n",
              "                                        cleaned_message  \n",
              "0     go jurong point crazy available bugis n great ...  \n",
              "1                               ok lar joking wif u oni  \n",
              "2     free entry 2 wkly comp win fa cup final tkts 2...  \n",
              "3                   u dun say early hor u c already say  \n",
              "4             nah nt think goes usf lives around though  \n",
              "...                                                 ...  \n",
              "5567  2nd time tried 2 contact u u å750 pound prize ...  \n",
              "5568                       ì_ b going esplanade fr home  \n",
              "5569                              pity mood suggestions  \n",
              "5570  guy bitching acted like interested buying some...  \n",
              "5571                                     rofl true name  \n",
              "\n",
              "[5565 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38d5bd5a-04a4-4b07-aaac-cab6cb42a93b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>message</th>\n",
              "      <th>cleaned_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>go jurong point crazy available bugis n great ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>u dun say early hor u c already say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>nah nt think goes usf lives around though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>1</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>2nd time tried 2 contact u u å750 pound prize ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>0</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>ì_ b going esplanade fr home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>0</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>pity mood suggestions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>0</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>guy bitching acted like interested buying some...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>0</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>rofl true name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5565 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38d5bd5a-04a4-4b07-aaac-cab6cb42a93b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-38d5bd5a-04a4-4b07-aaac-cab6cb42a93b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-38d5bd5a-04a4-4b07-aaac-cab6cb42a93b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLPWWiNtLBmK"
      },
      "source": [
        "- Performing train-test split\n",
        "- with [CountVectorization](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
        "- and StandardScaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmqZk9oQG6Gw",
        "outputId": "03a07655-ba7c-4205-ef61-78514ff851ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(4173,), (1392,)]\n",
            "[(4173, 7622), (1392, 7622)]\n",
            "<class 'scipy.sparse._csr.csr_matrix'>\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_X_train, df_X_test, y_train, y_test = train_test_split(df['cleaned_message'], df['type'],\n",
        "                                                          test_size=0.25, random_state=47)\n",
        "print([np.shape(df_X_train), np.shape(df_X_test)])\n",
        "\n",
        "# CountVectorizer\n",
        "f = feature_extraction.text.CountVectorizer()\n",
        "X_train = f.fit_transform(df_X_train)\n",
        "X_test = f.transform(df_X_test)\n",
        "\n",
        "# StandardScaler\n",
        "scaler = StandardScaler(with_mean=False) # problems with dense matrix\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "print([np.shape(X_train), np.shape(X_test)])\n",
        "print(type(X_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIALdxF1vM1Q"
      },
      "source": [
        "Let's train Linear SVM on the given Spam/Ham data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "id": "0c_RFq2nrQak",
        "outputId": "9b0e9b2b-615a-4479-8f61-485c4531b8c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3,\n",
              "             estimator=SVC(class_weight={0: 0.1, 1: 0.5}, kernel='linear'),\n",
              "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10]}, scoring='f1')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=SVC(class_weight={0: 0.1, 1: 0.5}, kernel=&#x27;linear&#x27;),\n",
              "             param_grid={&#x27;C&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10]}, scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
              "             estimator=SVC(class_weight={0: 0.1, 1: 0.5}, kernel=&#x27;linear&#x27;),\n",
              "             param_grid={&#x27;C&#x27;: [0.0001, 0.001, 0.01, 0.1, 1, 10]}, scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight={0: 0.1, 1: 0.5}, kernel=&#x27;linear&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(class_weight={0: 0.1, 1: 0.5}, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# SVC\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "          'C': [1e-4,  0.001, 0.01, 0.1, 1,10] # which hyperparam value of C do you think will work well?\n",
        "         }\n",
        "\n",
        "svc = SVC(class_weight={ 0:0.1, 1:0.5 }, kernel='linear')\n",
        "clf = GridSearchCV(svc, params, scoring = \"f1\", cv=3)\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFpdPOIoypXt",
        "outputId": "fb452052-53cf-4b66-b39e-625bc93b9e50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters:{'C': 0.0001} \n",
            " Mean score: 0.6566305780023073 \n",
            " Rank: 6\n",
            "Parameters:{'C': 0.001} \n",
            " Mean score: 0.7742322485787693 \n",
            " Rank: 1\n",
            "Parameters:{'C': 0.01} \n",
            " Mean score: 0.767533370474547 \n",
            " Rank: 2\n",
            "Parameters:{'C': 0.1} \n",
            " Mean score: 0.7649416969151316 \n",
            " Rank: 3\n",
            "Parameters:{'C': 1} \n",
            " Mean score: 0.7649416969151316 \n",
            " Rank: 3\n",
            "Parameters:{'C': 10} \n",
            " Mean score: 0.7649416969151316 \n",
            " Rank: 3\n"
          ]
        }
      ],
      "source": [
        "res = clf.cv_results_\n",
        "\n",
        "for i in range(len(res[\"params\"])):\n",
        "  print(f\"Parameters:{res['params'][i]} \\n Mean score: {res['mean_test_score'][i]} \\n Rank: {res['rank_test_score'][i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFcTYQgWK47H"
      },
      "source": [
        "As you can see,\n",
        "- we get the best performance when $C=0.001$,\n",
        "- with F1 Score of 0.77.\n",
        "\n",
        "\\\n",
        "Now implementing this SVM on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE5d2TikR7bg",
        "outputId": "84153fa8-2a16-4cf4-8eff-8e6352991218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8835820895522388\n"
          ]
        }
      ],
      "source": [
        "svc = SVC(C=0.001,class_weight={ 0:0.1, 1:0.5 }, kernel='linear')\n",
        "\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svc.predict(X_test)\n",
        "\n",
        "print(metrics.f1_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXbqg2OKJ3Xc"
      },
      "source": [
        "Linear SVM performs much well\n",
        "- on the Spam/Ham data\n",
        "- with F1 Score of 0.88\n",
        "- when using class weights."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Wxw5AaHMFNzv",
        "JP8teuA0xWYq",
        "3OJQU1Z6K5by"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}