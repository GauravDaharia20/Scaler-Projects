ssh -i ec2-feb7.pem ubuntu@52.5.8.91

install docker
	 1. install docker repository
	 2. install docker 

before using docker use below command 

sudo usermod -a -G docker ubuntu

sudo reboot

docker pull gaurav20/loan_app

docker image ls

docker run -d -p host-port:container-port your-image 

Method to use ECR

Push your image to ecr.
then we can deploy ecs

1. pip install aws cli 
2. aws configure

assoc .py=pyautofile
ftype pyautofile="C:\Users\gaura\anaconda3\python.exe" "%1" %*



PRoject
1. problem satement
2. data pipeline
3. solution apporach
4. impact or success metrics


	Programming Languages: JavaScript, TypeScript, Python, SQL, Shell Script, C++
	Libraries: TensorFlow, Keras, NumPy, Pandas, Scipy, Seaborn
	Databases: Oracle SQL, MySQL, Redshift (AWS)
	Tools/Platforms: Git, GitLab, Tableau, Excel, GCP (BigQuery, Data Flow)
	Skills: Statistical Analysis, Exploratory Data Analysis
	Machine Learning: Linear Regression, Logistic Regression, Random Forest, Ensembling Techniques, SVM


	Development of Deep Neural Network: I designed and developed a deep neural network using Python, TensorFlow, Keras, and NLTK. The objective was to predict diseases based on symptoms reported by users. This network leveraged state-of-the-art tools and technologies in the field of machine learning and natural language processing (NLP).
	Model Accuracy: The deep neural network I created achieved an impressive accuracy rate of 95% in predicting diseases from the symptoms provided to it. This high accuracy level underscores the effectiveness of the model in assisting with disease diagnosis and decision-making.
	User-Friendly Website: To enhance the user experience, I built a user-friendly website using Angular. This website served as an interface for users to input symptoms and receive predictions. The design and usability of the site were tailored to make the interaction as seamless as possible.
Machine Learning Model Hosting: I developed and implemented an API using FAST API to host the machine learning model on a live website. This allowed for real-time predictions and seamless integration with the user interface. The hosting of the model using FAST API contributed to the reliability and scalability of the system.





awk 'NR==3,NR==6 {print $0}' <filename>

print all values 

awk '{print}' emp.txt

awk '/manager/{print}' <filename> -> this will print all manager contained string


awk {print $1,$4} <file> > temp.txt


Number of records 
1 record1 

awk '{print NR, $0}' <file>

last field 

awk '{print $1 $NF}' <file>

awk '{print NR "- "$1}' geek.txt

awk '{print $2}' geek.txt

awk '{if length($0)>max' max = length($0)} end {print max}' geek.txt

awk '{print NR}' geek.txt

check any string in column 
awk '{if $1=="B6"} print $0;' file


#!/bin/bash

echo "first file $0"
echo "second file $1"

./arg.sh "A" "B"

data processsing 

preprocess.sh
#!/bin/bash 
echo $0+20

./preprocess.sh 50 -> 70

$sed 's/unix/linux' <filename> -> replace unix with linux 

$sed 's/unix/linux/2' <filename> ->replace first or second occurence  

$sed 's/unix/linux/g'<filename> global replacement

$sed 's/unix/linux/3g' <filename> every 3rd occurence

$sed '3 s/unix/linux/'

range replacement 
$sed '1,3 s/unix/linux/' <filename>

delete a particular line 

sed '5d' <filename>

range delete 
sed '3,6d' <filename>

sed '$d' <filename> last line 

sed '12,$d'<filename> -> nth line from last

sed '/abc/d' <filename>